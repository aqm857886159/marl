{
  "artifacts": [],
  "command": "my_main",
  "experiment": {
    "base_dir": "C:\\Users\\23732\\Desktop\\MARL\u8fb9\u7f18\u8c03\u5ea6\u5b9e\u9a8c\\pymarl\\src",
    "dependencies": [
      "numpy==1.26.4",
      "pyyaml==6.0.3",
      "sacred==0.8.7",
      "torch==2.4.1+cu121"
    ],
    "mainfile": "main.py",
    "name": "pymarl",
    "repositories": [
      {
        "commit": "260b8cfc9d39596a038325418b727fa4f73d3a7a",
        "dirty": false,
        "url": "https://github.com/aqm857886159/marl.git"
      },
      {
        "commit": "260b8cfc9d39596a038325418b727fa4f73d3a7a",
        "dirty": false,
        "url": "https://github.com/aqm857886159/marl.git"
      },
      {
        "commit": "260b8cfc9d39596a038325418b727fa4f73d3a7a",
        "dirty": false,
        "url": "https://github.com/aqm857886159/marl.git"
      }
    ],
    "sources": [
      [
        "main.py",
        "_sources\\main_d631a413c65497fadeab47680021f4e3.py"
      ],
      [
        "run.py",
        "_sources\\run_b0aaad29119fb7a2d25dd2f9c859d27e.py"
      ],
      [
        "utils\\logging.py",
        "_sources\\logging_a21c82d8525261657061a83f81fbd345.py"
      ]
    ]
  },
  "fail_trace": [
    "Traceback (most recent call last):\n",
    "  File \"C:\\Users\\23732\\anaconda3\\envs\\marl\\lib\\site-packages\\sacred\\config\\captured_function.py\", line 42, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"C:\\Users\\23732\\Desktop\\MARL\u8fb9\u7f18\u8c03\u5ea6\u5b9e\u9a8c\\pymarl\\src\\main.py\", line 35, in my_main\n    run(_run, config, _log)\n",
    "  File \"C:\\Users\\23732\\Desktop\\MARL\u8fb9\u7f18\u8c03\u5ea6\u5b9e\u9a8c\\pymarl\\src\\run.py\", line 48, in run\n    run_sequential(args=args, logger=logger)\n",
    "  File \"C:\\Users\\23732\\Desktop\\MARL\u8fb9\u7f18\u8c03\u5ea6\u5b9e\u9a8c\\pymarl\\src\\run.py\", line 166, in run_sequential\n    episode_batch = runner.run(test_mode=False)\n",
    "  File \"C:\\Users\\23732\\Desktop\\MARL\u8fb9\u7f18\u8c03\u5ea6\u5b9e\u9a8c\\pymarl\\src\\runners\\episode_runner.py\", line 63, in run\n    self.batch.update(pre_transition_data, ts=self.t)\n",
    "  File \"C:\\Users\\23732\\Desktop\\MARL\u8fb9\u7f18\u8c03\u5ea6\u5b9e\u9a8c\\pymarl\\src\\components\\episode_buffer.py\", line 103, in update\n    v = th.tensor(v, dtype=dtype, device=self.device)\n",
    "RuntimeError: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
  ],
  "heartbeat": "2025-12-03T16:41:05.158025",
  "host": {
    "ENV": {},
    "cpu": "13th Gen Intel(R) Core(TM) i9-13900H",
    "gpus": {
      "driver_version": "566.26",
      "gpus": [
        {
          "model": "NVIDIA GeForce RTX 4060 Laptop GPU",
          "persistence_mode": false,
          "total_memory": 8188
        }
      ]
    },
    "hostname": "aqmthinkbook",
    "os": [
      "Windows",
      "Windows-10-10.0.26100-SP0"
    ],
    "python_version": "3.10.19"
  },
  "meta": {
    "command": "my_main",
    "config_updates": {
      "seed": 3
    },
    "named_configs": [],
    "options": {
      "--beat-interval": null,
      "--capture": null,
      "--comment": null,
      "--debug": false,
      "--enforce_clean": false,
      "--file_storage": null,
      "--force": false,
      "--help": false,
      "--id": null,
      "--loglevel": null,
      "--mongo_db": null,
      "--name": null,
      "--pdb": false,
      "--print-config": false,
      "--priority": null,
      "--queue": false,
      "--s3": null,
      "--sql": null,
      "--tiny_db": null,
      "--unobserved": false,
      "COMMAND": null,
      "UPDATE": [
        "seed=3"
      ],
      "help": false,
      "with": true
    }
  },
  "resources": [],
  "result": null,
  "start_time": "2025-12-03T16:38:54.200062",
  "status": "FAILED",
  "stop_time": "2025-12-03T16:41:05.162026"
}